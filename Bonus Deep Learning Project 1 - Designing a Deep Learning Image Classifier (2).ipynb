{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df26f1c-c261-4823-abe0-dcadeb1a6469",
   "metadata": {},
   "source": [
    "# Bonus Deep Learning Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e765695-bc7c-4876-bcce-90be26e0549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import gzip\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea32885-2f6c-47c2-b092-e0e7b10851a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist(path='mnist'):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "    files = {\n",
    "        \"train_images\": \"train-images-idx3-ubyte.gz\",\n",
    "        \"train_labels\": \"train-labels-idx1-ubyte.gz\",\n",
    "        \"test_images\": \"t10k-images-idx3-ubyte.gz\",\n",
    "        \"test_labels\": \"t10k-labels-idx1-ubyte.gz\"\n",
    "    }\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        filepath = os.path.join(path, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "            \n",
    "    print(\"MNIST dataset downloaded.\")\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "        images = images.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "        return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "def load_mnist(path='mnist'):\n",
    "    download_mnist(path)\n",
    "    train_images = load_mnist_images(os.path.join(path, \"train-images-idx3-ubyte.gz\"))\n",
    "    train_labels = load_mnist_labels(os.path.join(path, \"train-labels-idx1-ubyte.gz\"))\n",
    "    test_images = load_mnist_images(os.path.join(path, \"t10k-images-idx3-ubyte.gz\"))\n",
    "    test_labels = load_mnist_labels(os.path.join(path, \"t10k-labels-idx1-ubyte.gz\"))\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad8bed3-4a09-456d-b19a-e2cf38670e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST training images (for speed, we use a small subset)\n",
    "train_images, train_labels, test_images, test_labels = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c9f56-0c37-4e95-9f8d-6814b7041aaf",
   "metadata": {},
   "source": [
    "# Core Layer Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c2f9ce-099e-40fb-986b-cc257f9bc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.W = np.random.randn(in_dim, out_dim) * 0.02\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.z = x @ self.W + self.b  \n",
    "        \n",
    "        return self.z \n",
    "\n",
    "    def backward(self, grad, lr):\n",
    "        # Calculate gradients\n",
    "        dW = self.x.T.dot(grad)\n",
    "        db = np.sum(grad, axis = 0, keepdims = True)\n",
    "        dx = grad.dot(self.W.T)\n",
    "\n",
    "        # Gradient updates\n",
    "        self.W -= lr * dW\n",
    "        self.b -= lr * db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2c38a2-bf89-4e11-8d3a-6c9733c3481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, in_ch, out_ch, k, stride = 1, pad = 0):\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.W = np.random.randn(out_ch, in_ch, k, k) * 0.02\n",
    "        self.b = np.zeros((out_ch,))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, width = x.shape\n",
    "        F, _, k, _ = self.W.shape\n",
    "\n",
    "        h_out = ((H + (2 * self.pad) - k) // self.stride) + 1\n",
    "        w_out = ((width + (2 * self.pad) - k) // self.stride) + 1\n",
    "\n",
    "        # Now we pad x\n",
    "        x_padded = np.pad(\n",
    "                x,\n",
    "                pad_width=((0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)),\n",
    "                mode='constant',\n",
    "                constant_values=0\n",
    "            )\n",
    "\n",
    "        out = np.zeros((N, self.W.shape[0], h_out, w_out), dtype = x.dtype)\n",
    "\n",
    "        for m in range(N):\n",
    "            for n in range(F):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vertical = i * self.stride\n",
    "                        horizontal = j * self.stride\n",
    "\n",
    "                        area = x_padded[m, :, vertical : vertical + k, horizontal : horizontal + k]\n",
    "                        out[m, n, i, j] = np.sum(area * self.W[n]) + self.b[n]\n",
    "\n",
    "        self.x_padded = x_padded\n",
    "        self.x_shape = x.shape\n",
    "                        \n",
    "        return out\n",
    "                \n",
    "\n",
    "    def backward(self, grad, lr):\n",
    "        N, C, H_pad, W_pad = self.x_padded.shape\n",
    "        x_padded = self.x_padded\n",
    "        F, _, k, _ = self.W.shape \n",
    "        _, _, h_out, w_out = grad.shape\n",
    "\n",
    "        # Initializing gradients\n",
    "        dW = np.zeros_like(self.W)           \n",
    "        db = np.zeros_like(self.b)         \n",
    "        dx_padded = np.zeros_like(x_padded) \n",
    "\n",
    "        for m in range(N):\n",
    "            for n in range(F):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vert_start = i * self.stride\n",
    "                        horiz_start = j * self.stride\n",
    "\n",
    "                        area = x_padded[m, :, vert_start:vert_start + k, horiz_start:horiz_start + k]\n",
    "                        dW[n] += grad[m, n, i, j] * area\n",
    "                        db[n] += grad[m, n, i, j]\n",
    "\n",
    "                        dx_padded[m, :, vert_start:vert_start + k, horiz_start:horiz_start + k] += grad[m, n, i, j] * self.W[n]\n",
    "                        \n",
    "        # Unpad\n",
    "        if self.pad>0:\n",
    "            dx = dx_padded[:,:,self.pad:-self.pad,self.pad:-self.pad]\n",
    "        else:\n",
    "            dx = dx_padded\n",
    "            \n",
    "        # Update Gradients\n",
    "        self.W -= lr * dW\n",
    "        self.b -= lr * db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4225ba-2ac1-4431-8b91-ff40f6790bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPool2D:\n",
    "    def __init__(self, k, stride = 1, pad = 0):\n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        k = self.k\n",
    "\n",
    "        h_out = ((H + 2*self.pad - k) // self.stride) + 1\n",
    "        w_out = ((W + 2*self.pad - k) // self.stride) + 1\n",
    "\n",
    "        # Pad Input\n",
    "        x_padded = np.pad(\n",
    "            x,\n",
    "            pad_width=((0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)),\n",
    "            mode = 'constant',\n",
    "            constant_values = 0\n",
    "        )\n",
    "\n",
    "        out = np.zeros((N, C, h_out, w_out), dtype = x.dtype)\n",
    "\n",
    "        for m in range(N):\n",
    "            for n in range(C):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vert_start = i * self.stride\n",
    "                        horiz_start = j * self.stride\n",
    "\n",
    "                        region = x_padded[m, n, vert_start:vert_start+k, horiz_start:horiz_start+k]\n",
    "                        out[m, n, i, j] = np.mean(region)\n",
    "\n",
    "        self.x_padded = x_padded\n",
    "        self.x_shape = x.shape\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad):\n",
    "        N, C, H_pad, W_pad = self.x_padded.shape\n",
    "        k = self.k\n",
    "        _, _, h_out, w_out = grad.shape\n",
    "\n",
    "        dx_padded = np.zeros_like(self.x_padded)\n",
    "\n",
    "        for m in range(N):\n",
    "            for n in range(C):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vert_start = i * self.stride\n",
    "                        horiz_start = j * self.stride\n",
    "\n",
    "                        dx_padded[m, n, vert_start:vert_start+k, horiz_start:horiz_start+k] += grad[m,n,i,j] / (k*k)\n",
    "\n",
    "        # unpad\n",
    "        if self.pad > 0:\n",
    "            dx = dx_padded[:, :, self.pad:-self.pad, self.pad:-self.pad]\n",
    "        else:\n",
    "            dx = dx_padded\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4a208-11d1-4cf2-b97e-84c0805e406b",
   "metadata": {},
   "source": [
    "# Activation Functions & Their Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a8f733-b02e-47ca-9eca-e6875edd499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def sigmoid_deriv(x):\n",
    "    s = sigmoid(x)\n",
    "    return s*(1-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20387274-5bb6-4ad1-8d2a-c51fcb3b2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): \n",
    "    return np.maximum(0,x)\n",
    "    \n",
    "def relu_deriv(x): \n",
    "    return (x>0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50164d0e-5e0f-4c82-998f-9ec034a37c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x): \n",
    "    return np.tanh(x)\n",
    "    \n",
    "def tanh_deriv(x): \n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250898c-9a95-49ef-96b5-ab75fa561d4f",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da308bc-16a0-4f41-87ee-ea1485229b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2D(in_ch = 1, out_ch = 2, k =3, stride = 1, pad = 1)\n",
    "        self.pool = AvgPool2D(k = 2, stride = 2)\n",
    "        self.conv2 = Conv2D(in_ch = 2, out_ch = 10, k = 1, stride = 1, pad = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = self.conv1.forward(x)\n",
    "        a1 = sigmoid(self.z1)               # (N,2,28,28)\n",
    "        \n",
    "        p  = self.pool.forward(a1)     # (N,2,14,14)\n",
    "        z2 = self.conv2.forward(p)     # (N,10,14,14)\n",
    "        \n",
    "        self.logits = z2.mean(axis=(2,3)) # Global average pool to get (N, 10)\n",
    "\n",
    "        # Softmax\n",
    "        ex = np.exp(self.logits - self.logits.max(axis = 1,keepdims = True))\n",
    "        self.probs = ex / ex.sum(axis = 1,keepdims = True)\n",
    "        \n",
    "        return self.probs\n",
    "\n",
    "    def backward(self, y_true, lr):\n",
    "        N = y_true.shape[0]\n",
    "\n",
    "        grad_logits = (self.probs - y_true) / N\n",
    "        grad_z2 = grad_logits[:, :, None, None] / (14 * 14) # Expanding the gradient across 14 x 14 spatial map\n",
    "\n",
    "        grad_p = self.conv2.backward(grad_z2, lr) # Shape (N, 2, 14, 14)\n",
    "\n",
    "        grad_a1 = self.pool.backward(grad_p)\n",
    "        grad_z1 = grad_a1 * sigmoid_deriv(self.z1)\n",
    "\n",
    "        _ = self.conv1.backward(grad_z1, lr) # Backpropogating through conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51cc0b8-1ac6-463d-b392-0e91359c4a2b",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4ea0a3-ce0e-40f9-be6a-dae829cf9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross-Entropy Loss Function\n",
    "def bce_loss(y_pred, y_true):\n",
    "    eps = 1e-8\n",
    "    return -np.mean(y_true * np.log(y_pred + eps) + (1 - y_true) * np.log(1 - y_pred + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e108ee-d54a-4192-a595-5c415598fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Function\n",
    "def accuracy(probs, y_true):\n",
    "    return np.mean(np.argmax(probs, axis=1) == np.argmax(y_true, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc5598fc-5551-4e16-9d46-d7dc02611a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_images, train_labels, test_images, test_labels, epochs = 50, batch_size = 64, lr = 1e-3):\n",
    "    N = train_images.shape[0]\n",
    "    \n",
    "    # One-hot encode labels\n",
    "    Y_train = np.eye(10)[train_labels]\n",
    "    Y_test  = np.eye(10)[test_labels]\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'test_loss':  [], 'test_acc':  []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        perm = np.random.permutation(N)\n",
    "        losses, accs = [], []\n",
    "\n",
    "        for i in range(0, N, batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            x  = train_images[idx][:, None, :, :]  \n",
    "            y  = Y_train[idx]\n",
    "\n",
    "            probs = model.forward(x)\n",
    "            loss  = bce_loss(probs, y)\n",
    "            acc   = accuracy(probs, y)\n",
    "            model.backward(y, lr)\n",
    "\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "\n",
    "        train_loss = np.mean(losses)\n",
    "        train_acc  = np.mean(accs)\n",
    "\n",
    "        probs_test = model.forward(test_images[:, None, :, :])\n",
    "        test_loss  = bce_loss(probs_test, Y_test)\n",
    "        test_acc   = accuracy(probs_test, Y_test)\n",
    "\n",
    "        # Record values\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs}  \"\n",
    "              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f}  \"\n",
    "              f\"test_loss={test_loss:.4f}, test_acc={test_acc:.4f}\")\n",
    "\n",
    "    # Plotting\n",
    "    epochs_range = np.arange(1, epochs+1)\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs_range, history['test_loss'],  label='Test Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "    plt.title('Loss'); plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs_range, history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(epochs_range, history['test_acc'],  label='Test Accuracy')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy'); plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a2c088-7f8c-4d89-a459-c93a102d2548",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58624cb-61ae-4f90-a524-ab0a20345263",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "history = train(\n",
    "    cnn,\n",
    "    train_images, train_labels,\n",
    "    test_images,  test_labels,\n",
    "    epochs = 100,\n",
    "    batch_size = 128,\n",
    "    lr = 1e-3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
