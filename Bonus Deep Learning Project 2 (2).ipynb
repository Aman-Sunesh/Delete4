{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df26f1c-c261-4823-abe0-dcadeb1a6469",
   "metadata": {},
   "source": [
    "# Bonus Deep Learning Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e765695-bc7c-4876-bcce-90be26e0549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import gzip\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea32885-2f6c-47c2-b092-e0e7b10851a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist(path='mnist'):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "    files = {\n",
    "        \"train_images\": \"train-images-idx3-ubyte.gz\",\n",
    "        \"train_labels\": \"train-labels-idx1-ubyte.gz\",\n",
    "        \"test_images\": \"t10k-images-idx3-ubyte.gz\",\n",
    "        \"test_labels\": \"t10k-labels-idx1-ubyte.gz\"\n",
    "    }\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        filepath = os.path.join(path, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "            \n",
    "    print(\"MNIST dataset downloaded.\")\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "        images = images.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "        return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "def load_mnist(path='mnist'):\n",
    "    download_mnist(path)\n",
    "    train_images = load_mnist_images(os.path.join(path, \"train-images-idx3-ubyte.gz\"))\n",
    "    train_labels = load_mnist_labels(os.path.join(path, \"train-labels-idx1-ubyte.gz\"))\n",
    "    test_images = load_mnist_images(os.path.join(path, \"t10k-images-idx3-ubyte.gz\"))\n",
    "    test_labels = load_mnist_labels(os.path.join(path, \"t10k-labels-idx1-ubyte.gz\"))\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad8bed3-4a09-456d-b19a-e2cf38670e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST training images (for speed, we use a small subset)\n",
    "train_images, train_labels, test_images, test_labels = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c9f56-0c37-4e95-9f8d-6814b7041aaf",
   "metadata": {},
   "source": [
    "# Core Layer Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c2f9ce-099e-40fb-986b-cc257f9bc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.W = np.random.randn(in_dim, out_dim) * 0.02\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.z = x @ self.W + self.b  \n",
    "        \n",
    "        return self.z \n",
    "\n",
    "    def backward(self, grad, lr):\n",
    "        # Calculate gradients\n",
    "        dW = self.x.T.dot(grad)\n",
    "        db = np.sum(grad, axis = 0, keepdims = True)\n",
    "        dx = grad.dot(self.W.T)\n",
    "\n",
    "        # Gradient updates\n",
    "        self.W -= lr * dW\n",
    "        self.b -= lr * db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2c38a2-bf89-4e11-8d3a-6c9733c3481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, in_ch, out_ch, k, stride = 1, pad = 0):\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.W = np.random.randn(out_ch, in_ch, k, k) * 0.02\n",
    "        self.b = np.zeros((out_ch,))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, width = x.shape\n",
    "        F, _, k, _ = self.W.shape\n",
    "\n",
    "        h_out = ((H + (2 * self.pad) - k) // self.stride) + 1\n",
    "        w_out = ((width + (2 * self.pad) - k) // self.stride) + 1\n",
    "\n",
    "        # Now we pad x\n",
    "        x_padded = np.pad(\n",
    "                x,\n",
    "                pad_width=((0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)),\n",
    "                mode='constant',\n",
    "                constant_values=0\n",
    "            )\n",
    "\n",
    "        out = np.zeros((N, self.W.shape[0], h_out, w_out), dtype = x.dtype)\n",
    "\n",
    "        for m in range(N):\n",
    "            for n in range(F):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vertical = i * self.stride\n",
    "                        horizontal = j * self.stride\n",
    "\n",
    "                        area = x_padded[m, :, vertical : vertical + k, horizontal : horizontal + k]\n",
    "                        out[m, n, i, j] = np.sum(area * self.W[n]) + self.b[n]\n",
    "\n",
    "        self.x_padded = x_padded\n",
    "        self.x_shape = x.shape\n",
    "                        \n",
    "        return out\n",
    "                \n",
    "\n",
    "    def backward(self, grad, lr):\n",
    "        N, C, H_pad, W_pad = self.x_padded.shape\n",
    "        x_padded = self.x_padded\n",
    "        F, _, k, _ = self.W.shape \n",
    "        _, _, h_out, w_out = grad.shape\n",
    "\n",
    "        # Initializing gradients\n",
    "        dW = np.zeros_like(self.W)           \n",
    "        db = np.zeros_like(self.b)         \n",
    "        dx_padded = np.zeros_like(x_padded) \n",
    "\n",
    "        for m in range(N):\n",
    "            for n in range(F):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vert_start = i * self.stride\n",
    "                        horiz_start = j * self.stride\n",
    "\n",
    "                        area = x_padded[m, :, vert_start:vert_start + k, horiz_start:horiz_start + k]\n",
    "                        dW[n] += grad[m, n, i, j] * area\n",
    "                        db[n] += grad[m, n, i, j]\n",
    "\n",
    "                        dx_padded[m, :, vert_start:vert_start + k, horiz_start:horiz_start + k] += grad[m, n, i, j] * self.W[n]\n",
    "                        \n",
    "        # Unpad\n",
    "        if self.pad>0:\n",
    "            dx = dx_padded[:,:,self.pad:-self.pad,self.pad:-self.pad]\n",
    "        else:\n",
    "            dx = dx_padded\n",
    "            \n",
    "        # Update Gradients\n",
    "        self.W -= lr * dW\n",
    "        self.b -= lr * db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4225ba-2ac1-4431-8b91-ff40f6790bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, k, stride = 1, pad = 0):\n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, width = x.shape\n",
    "        k = self.k\n",
    "\n",
    "        h_out = ((H + 2*self.pad - k) // self.stride) + 1\n",
    "        w_out = ((width + 2*self.pad - k) // self.stride) + 1\n",
    "\n",
    "        # Pad Input\n",
    "        x_padded = np.pad(\n",
    "            x,\n",
    "            pad_width=((0,0), (0,0), (self.pad,self.pad), (self.pad,self.pad)),\n",
    "            mode='constant',\n",
    "            constant_values = 0\n",
    "        )\n",
    "\n",
    "        out = np.zeros((N, C, h_out, w_out), dtype = x.dtype)\n",
    "\n",
    "        for m in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vert_start = i * self.stride\n",
    "                        horiz_start = j * self.stride\n",
    "\n",
    "                        region = x_padded[m, c, vert_start:vert_start+k, horiz_start:horiz_start+k]\n",
    "                        out[m, c, i, j] = np.max(region)\n",
    "\n",
    "        self.x_padded = x_padded\n",
    "        self.x_shape = x.shape\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad):\n",
    "        N, C, H_pad, W_pad = self.x_padded.shape\n",
    "        k = self.k\n",
    "        _, _, h_out, w_out = grad.shape\n",
    "\n",
    "        dx_padded = np.zeros_like(self.x_padded)\n",
    "\n",
    "        for m in range(N):\n",
    "            for c in range(C):\n",
    "                for i in range(h_out):\n",
    "                    for j in range(w_out):\n",
    "                        vert_start = i * self.stride\n",
    "                        horiz_start = j * self.stride\n",
    "\n",
    "                        region = self.x_padded[m, c, vert_start:vert_start+k, horiz_start:horiz_start+k]\n",
    "                        max_val = np.max(region)\n",
    "                        mask = (region == max_val)\n",
    "\n",
    "                        dx_padded[m, c, vert_start:vert_start+k, horiz_start:horiz_start+k] += mask * grad[m, c, i, j]\n",
    "\n",
    "        # unpad\n",
    "        if self.pad > 0:\n",
    "            dx = dx_padded[:, :, self.pad:-self.pad, self.pad:-self.pad]\n",
    "        else:\n",
    "            dx = dx_padded\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4a208-11d1-4cf2-b97e-84c0805e406b",
   "metadata": {},
   "source": [
    "# Activation Functions & Their Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a8f733-b02e-47ca-9eca-e6875edd499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def sigmoid_deriv(x):\n",
    "    s = sigmoid(x)\n",
    "    return s*(1-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20387274-5bb6-4ad1-8d2a-c51fcb3b2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): \n",
    "    return np.maximum(0,x)\n",
    "    \n",
    "def relu_deriv(x): \n",
    "    return (x>0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50164d0e-5e0f-4c82-998f-9ec034a37c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x): \n",
    "    return np.tanh(x)\n",
    "    \n",
    "def tanh_deriv(x): \n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13bfa3c-609b-4cbe-8a6c-ba7be90e3212",
   "metadata": {},
   "source": [
    "# Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66d86c2-7072-4e89-ba1c-f96a2b8688cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, dim_z):\n",
    "        self.fc1 = FullyConnected(dim_z, 256)\n",
    "        self.fc2 = FullyConnected(256, 512)\n",
    "        self.fc3 = FullyConnected(512, 1024)\n",
    "        self.fc4 = FullyConnected(1024, 784) # 784 = 28*28 -> Dimension of MNIST images \n",
    "\n",
    "    def forward(self, z):\n",
    "        x = relu(self.fc1.forward(z))\n",
    "        x = relu(self.fc2.forward(x))\n",
    "        x = relu(self.fc3.forward(x))   \n",
    "        x = tanh(self.fc4.forward(x))\n",
    "        \n",
    "        return x.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def backward(self, grad_img, lr):\n",
    "        batch_size = grad_img.shape[0]\n",
    "        grad = grad_img.reshape(batch_size, 784)\n",
    "\n",
    "        d_tanh = tanh_deriv(self.fc4.z)      \n",
    "        grad = grad * d_tanh                 \n",
    "        grad = self.fc4.backward(grad, lr)    \n",
    "\n",
    "        d_relu3 = relu_deriv(self.fc3.z)       \n",
    "        grad = grad * d_relu3\n",
    "        grad = self.fc3.backward(grad, lr)     \n",
    "\n",
    "        d_relu2 = relu_deriv(self.fc2.z)      \n",
    "        grad = grad * d_relu2\n",
    "        grad = self.fc2.backward(grad, lr)     \n",
    "\n",
    "        d_relu1 = relu_deriv(self.fc1.z)     \n",
    "        grad = grad * d_relu1\n",
    "        _ = self.fc1.backward(grad, lr)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c1e57-432c-4d3d-acf5-25e7c0dbe27c",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8d3d61e-f616-4018-80ad-f10a93ee96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self):\n",
    "        self.fc1 = FullyConnected(784, 1024)\n",
    "        self.fc2 = FullyConnected(1024, 512)\n",
    "        self.fc3 = FullyConnected(512, 256)\n",
    "        self.fc4 = FullyConnected(256, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        batch = img.shape[0]\n",
    "        x = img.reshape(batch, 784)\n",
    "        x = relu(self.fc1.forward(x))\n",
    "        x = relu(self.fc2.forward(x))\n",
    "        x = relu(self.fc3.forward(x))\n",
    "        logit = self.fc4.forward(x)\n",
    "        \n",
    "        return sigmoid(logit)\n",
    "\n",
    "    def backward(self, upstream_grad, lr, update=True):\n",
    "        ds = sigmoid_deriv(self.fc4.z)\n",
    "        g  = upstream_grad * ds\n",
    "        g  = self.fc4.backward(g, lr if update else 0)\n",
    "\n",
    "        dr3 = relu_deriv(self.fc3.z)\n",
    "        g   = g * dr3\n",
    "        g   = self.fc3.backward(g, lr if update else 0)\n",
    "\n",
    "        dr2 = relu_deriv(self.fc2.z)\n",
    "        g   = g * dr2\n",
    "        g   = self.fc2.backward(g, lr if update else 0)\n",
    "\n",
    "        dr1 = relu_deriv(self.fc1.z)\n",
    "        g   = g * dr1\n",
    "        dx  = self.fc1.backward(g, lr if update else 0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51cc0b8-1ac6-463d-b392-0e91359c4a2b",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c3c8eed-bcd7-48d2-ad46-316cad2531fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross-Entropy Loss Function\n",
    "def bce_loss(y_pred, y_true):\n",
    "    eps = 1e-8\n",
    "    return -np.mean(y_true * np.log(y_pred + eps) + (1 - y_true) * np.log(1 - y_pred + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29856086-35a9-42c0-88b9-3e119ebbed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen, disc, images, epochs = 50, batch_size = 64, lr = 1e-5, dim_z = 100):\n",
    "    n = images.shape[0]\n",
    "    \n",
    "    # Histories\n",
    "    d_real_loss = []\n",
    "    d_fake_loss = []\n",
    "    g_loss_hist = []\n",
    "    d_real_acc = []\n",
    "    d_fake_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        perm = np.random.permutation(n)\n",
    "        for i in range(0, n, batch_size):\n",
    "            idx = perm[i : i + batch_size]\n",
    "            real = images[idx][:, None, :, :]\n",
    "\n",
    "            # Now we train D on real and fake images\n",
    "            z = np.random.randn(len(idx), dim_z)\n",
    "            fake = gen.forward(z)\n",
    "\n",
    "            d_out_real = disc.forward(real)\n",
    "            d_out_fake = disc.forward(fake)\n",
    "\n",
    "            # Losses\n",
    "            loss_real = bce_loss(d_out_real, np.ones_like(d_out_real))\n",
    "            loss_fake = bce_loss(d_out_fake, np.zeros_like(d_out_fake))\n",
    "\n",
    "            # Accuracies\n",
    "            ar = np.mean(d_out_real > 0.5)\n",
    "            af = np.mean(d_out_fake < 0.5)\n",
    "\n",
    "            grad_real = -(1 / (d_out_real + 1e-8))\n",
    "            grad_fake =  (1 / (1 - d_out_fake + 1e-8))\n",
    "\n",
    "            disc.backward(grad_real, lr, update=True)\n",
    "            disc.backward(grad_fake, lr, update=True)\n",
    "\n",
    "            # Now we train the generator by fooling the discriminator\n",
    "            z = np.random.randn(len(idx), dim_z)\n",
    "            fake2 = gen.forward(z)\n",
    "            d_out2 = disc.forward(fake2)\n",
    "\n",
    "            lg = bce_loss(d_out2, np.ones_like(d_out2))\n",
    "            grad_g = -(1 / (d_out2 + 1e-8))\n",
    "\n",
    "            # Backpropogate D followed by G\n",
    "            dx = disc.backward(grad_g, lr, update=False) # The discriminator is frozen here -> D's parameters stay fixed\n",
    "\n",
    "            # Chain through D's sigmoid \n",
    "            gen.backward(dx, lr)\n",
    "\n",
    "            # Now we store all the values for plotting\n",
    "            d_real_loss.append(loss_real)\n",
    "            d_fake_loss.append(loss_fake)\n",
    "            g_loss_hist.append(lg)\n",
    "            d_real_acc.append(ar)\n",
    "            d_fake_acc.append(af)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  \"\n",
    "              f\"D(real)={loss_real:.3f}  D(fake)={loss_fake:.3f}  G={lg:.3f}\")\n",
    "\n",
    "\n",
    "    # Losses\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(d_real_loss, label='D Real')\n",
    "    plt.plot(d_fake_loss, label='D Fake')\n",
    "    plt.plot(g_loss_hist,  label='G Loss')\n",
    "    plt.title('GAN Losses')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Accuracies\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(d_real_acc, label='D Acc on Real')\n",
    "    plt.plot(d_fake_acc, label='D Acc on Fake')\n",
    "    plt.title('Discriminator Accuracy')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a2c088-7f8c-4d89-a459-c93a102d2548",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227e8e5-ef33-4375-bb2f-b6ff09366d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50  D(real)=0.696  D(fake)=0.696  G=0.690\n",
      "Epoch 2/50  D(real)=0.698  D(fake)=0.698  G=0.688\n",
      "Epoch 3/50  D(real)=0.700  D(fake)=0.699  G=0.687\n"
     ]
    }
   ],
   "source": [
    "# Initiating the GAN\n",
    "dim_z = 100\n",
    "gen  = Generator(dim_z)\n",
    "disc = Discriminator()\n",
    "\n",
    "train(\n",
    "    gen, \n",
    "    disc, \n",
    "    train_images, \n",
    "    epochs     = 50, \n",
    "    batch_size = 64, \n",
    "    lr         = 1e-3, \n",
    "    dim_z      = dim_z\n",
    ")\n",
    "\n",
    "\n",
    "# After training the generator, we sample 16 random new z's and plot them\n",
    "n_samples = 16\n",
    "z = np.random.randn(n_samples, dim_z)\n",
    "fake_images = gen.forward(z)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(5,5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(fake_images[i,0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.suptitle(\"16 Generated Samples\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58624cb-61ae-4f90-a524-ab0a20345263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
